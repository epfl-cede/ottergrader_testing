{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22b7584d-cb71-45e1-aeba-594afbfaf208",
   "metadata": {},
   "source": [
    "# Grading students' submissions\n",
    "\n",
    "## Overall solution\n",
    "The CLI interface for the autograder works only with docker containers.  \n",
    "If we want to grade without containers, we will need to use other means.\n",
    "\n",
    "In this notebook, we use the `grade_submission` API.  \n",
    "But is is very limited:\n",
    "* It grades single submissions, not batches => we need to automate for batch + use parallel threads for performance?\n",
    "* It returns an object, that we will need to \"parse\" to reconstruct a moodle grading sheet (at least the CLI interface generates a CSV file... maybe it is possible to reuse part of the code?)\n",
    "\n",
    "TODO: for the moment I tested grading on individual .ipynb files, need to test on zip files\n",
    "\n",
    "## How to use it\n",
    "\n",
    "* Go into the dist folder, edit the student version of the assignment and use the public tests\n",
    "* Then try to grade it with the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7293fe1e-6a38-44d4-bd29-2e314faa18dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from otter.api import grade_submission\n",
    "import glob # to be able to refer to the autograder zip without having to check its name (changes each time it is generated)\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "from IPython.display import display, HTML\n",
    "def pretty_print(df):\n",
    "    return display( HTML( df.to_html().replace(\"\\\\n\",\"<br>\") ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057db5b0-aed6-44a2-8199-8bddb34ff1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "graderzip = glob.glob(\"dist/autograder/assignment-autograder_*.zip\")[0]\n",
    "graderzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162ab805-e6f9-4517-9323-0dc82496a414",
   "metadata": {},
   "outputs": [],
   "source": [
    "submissionlist = glob.glob(\"moodlesubmissions/*/*.ipynb\")\n",
    "submissionlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5cf3ec-c648-452a-99cc-27c95b32f2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: \n",
    "# - iterate over folders in submissions and retrieve the gradebook files\n",
    "# - build a feedback message with the messages of the test cases"
   ]
  },
  {
   "cell_type": "raw",
   "id": "49009ed5-73d0-4591-ba6d-aabd226c7847",
   "metadata": {},
   "source": [
    "grade_submission('submissions/student1234/assignment1234.ipynb', graderzip, quiet=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5695597-2987-460f-b968-8b74d9cb3c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for submission in submissionlist:\n",
    "    gradingoutput = grade_submission(submission, graderzip, quiet=True)\n",
    "    feedbackstr = \"Detailed feedback:\\n\" \n",
    "    for exercisename, exercise in gradingoutput.results.items():\n",
    "        feedbackstr += \"Exercise \"+ exercise.name + \": grade = \" + str(exercise.grade) + \" / \" + str(exercise.possible) + \"\\n\"\n",
    "    results.append([submission, gradingoutput.total, gradingoutput.possible, feedbackstr])\n",
    "\n",
    "resultsdf = pd.DataFrame(data=results, columns=[\"studentname\", \"grade\", \"maxgrade\", \"feedbackcomments\"])\n",
    "pretty_print(resultsdf)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f5f82cb2-f6a2-45fb-b2f6-199237d60926",
   "metadata": {},
   "source": [
    "print(resultsobject.total, \"/\", resultsobject.possible)\n",
    "for exercisename, exercise in resultsobject.results.items():\n",
    "    print(exercise.name)\n",
    "    print(exercise.grade)\n",
    "    print(exercise.possible)\n",
    "    print(exercise.passed_all)\n",
    "    print(exercise.passed_all_public)\n",
    "    for test_case_result in exercise.test_case_results:\n",
    "        print(\"\\t\", test_case_result.test_case.name)\n",
    "        print(\"\\t\", test_case_result.test_case.points)\n",
    "        print(\"\\t\", test_case_result.passed)\n",
    "        print(\"\\t\", test_case_result.test_case.success_message if test_case_result.passed else test_case_result.test_case.failure_message)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
